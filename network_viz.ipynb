{"metadata":{"orig_nbformat":4,"colab":{"authorship_tag":"ABX9TyOSxEIALiDmxBIQ2EnwyIcJ","collapsed_sections":[],"name":"bot_model_xiaodan.ipynb","provenance":[]},"interpreter":{"hash":"91fffe277e9b6148db7ae43dc415d7e953a3d11e32db61289ad389fe608b0878"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Code to (re)produce results in the paper \n\"Manipulating the Online Marketplace of Ideas\" \nby Xiaodan Lou, Alessandro Flammini, and Filippo Menczer\nhttps://arxiv.org/abs/1907.06130\n\nNotes:\n* Need Python 3.6 or later; eg: `module load python/3.6.6`\n* Remember link direction is following, opposite of info spread!\n* For large `n_humans`, it's much faster to run the simulations in parallel on a server or cluster, eg, one process for each combination of parameters (gamma, phi, mu...)\n\n\nParameters and default values:\n```\nn_humans = 1000 # 10k for paper\nbeta = 0.1 # bots/humans ratio; 0.1 for paper\np = 0.5 # for network clustering; 0.5 for paper\nk_out = 3 # average no. friends within humans & bots; 3 for paper\nalpha = 15 # depth of feed; 15 for paper\nmu = 0.75 # or 0.5? average prob of new meme vs retweet; or draw from empirical distribution\nphi = 1 # bot deception >= 1: meme fitness higher than quality\ngamma = 0.1 # infiltration: probability that a human follows each bot\nepsilon = 0.01 # threshold used to check for steady-state convergence\nn_runs = 10 # or 20? number of simulations to average results\ncsvfile = 'results.csv' # to save results for plotting\n```","metadata":{"colab_type":"text","id":"4VdiGhQd57n1"}},{"cell_type":"code","source":"import networkx as nx\nimport random\nimport numpy\nimport math\nimport statistics\nimport csv\nimport matplotlib.pyplot as plt\nfrom operator import itemgetter\nimport sys\nimport fcntl\nimport time\nimport bot_model\n\n%matplotlib inline\nassert(nx.__version__ >= '2.4')","metadata":{"colab":{},"colab_type":"code","id":"byMDogYTqly4","scrolled":true,"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# PRINT AVG Q","metadata":{"colab_type":"text","id":"PDTP02u76ZmW"}},{"cell_type":"code","source":"q, G_random_001_0 = bot_model.simulation(False, return_net=True, gamma=0.001, phi=0, mu=0.5)\nprint('average quality for gamma=0.001, phi=.1:', q)\n\nq, G_random_001_25 = bot_model.simulation(False, return_net=True, gamma=0.001, phi=.25, mu=0.5)\nprint('average quality for gamma=0.001, phi=.25:', q)\n\nq, G_random_001_50 = bot_model.simulation(False, return_net=True, gamma=0.001, phi=.5, mu=0.5)\nprint('average quality for gamma=0.001, phi=.5:', q)\n\nq, G_random_001_75 = bot_model.simulation(False, return_net=True, gamma=0.001, phi=.75, mu=0.5)\nprint('average quality for gamma=0.001, phi=.75:', q)\n\nq, G_random_001_100 = bot_model.simulation(False, return_net=True, gamma=0.001, phi=1, mu=0.5)\nprint('average quality for gamma=0.001, phi=1:', q)\n\nq, G_random_005_0 = bot_model.simulation(False, return_net=True, gamma=0.005, phi=0, mu=0.5)\nprint('average quality for gamma=0.005, phi=.0:', q)\n\nq, G_random_005_25 = bot_model.simulation(False, return_net=True, gamma=0.005, phi=.25, mu=0.5)\nprint('average quality for gamma=0.005, phi=.25:', q)\n\nq, G_random_005_50 = bot_model.simulation(False, return_net=True, gamma=0.005, phi=.5, mu=0.5)\nprint('average quality for gamma=0.005, phi=.5:', q)\n\nq, G_random_005_75 = bot_model.simulation(False, return_net=True, gamma=0.005, phi=.75, mu=0.5)\nprint('average quality for gamma=0.005, phi=.75:', q)\n\nq, G_random_005_100 = bot_model.simulation(False, return_net=True, gamma=0.005, phi=1, mu=0.5)\nprint('average quality for gamma=0.005, phi=1:', q)\n\nq, G_random_01_0 = bot_model.simulation(False, return_net=True, gamma=0.01, phi=0, mu=0.5)\nprint('average quality for gamma=0.01, phi=.0:', q)\n\nq, G_random_01_25 = bot_model.simulation(False, return_net=True, gamma=0.01, phi=.25, mu=0.5)\nprint('average quality for gamma=0.01, phi=.25:', q)\n\nq, G_random_01_50 = bot_model.simulation(False, return_net=True, gamma=0.01, phi=.5, mu=0.5)\nprint('average quality for gamma=0.01, phi=.5:', q)\n\nq, G_random_01_75 = bot_model.simulation(False, return_net=True, gamma=0.01, phi=.75, mu=0.5)\nprint('average quality for gamma=0.01, phi=.75:', q)\n\nq, G_random_01_100 = bot_model.simulation(False, return_net=True, gamma=0.01, phi=1, mu=0.5)\nprint('average quality for gamma=0.01, phi=1:', q)","metadata":{"colab":{},"colab_type":"code","id":"nlK_GvdCPXGl","trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"average quality for gamma=0.001, phi=.1: 0.11570984036014151\naverage quality for gamma=0.001, phi=.25: 0.2790165214448891\naverage quality for gamma=0.001, phi=.5: 0.28759382930151345\naverage quality for gamma=0.001, phi=.75: 0.28583695054916053\naverage quality for gamma=0.001, phi=1: 0.3392304050351733\naverage quality for gamma=0.005, phi=.0: 0.36286457470305766\naverage quality for gamma=0.005, phi=.25: 0.08653842765415258\naverage quality for gamma=0.005, phi=.5: 0.297727246684507\naverage quality for gamma=0.005, phi=.75: 0.08073598682982884\naverage quality for gamma=0.005, phi=1: 0.1658634683047756\naverage quality for gamma=0.01, phi=.0: 0.1620412979110434\naverage quality for gamma=0.01, phi=.25: 0.08772057133670405\naverage quality for gamma=0.01, phi=.5: 0.06789776290681895\naverage quality for gamma=0.01, phi=.75: 0.08371482131179867\naverage quality for gamma=0.01, phi=1: 0.0906911948093212\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]}]}